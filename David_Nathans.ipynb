{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a805274-d7bb-4fd5-9513-6e2ba6b21f46",
   "metadata": {},
   "source": [
    "Get list of publication for given author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90794a8d-ccd4-4ed4-aa76-900801b42493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "author_id = 'A5113797452'\n",
    "\n",
    "url = f'https://api.openalex.org/authors/{author_id}/works'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e1a1cfe-0585-4d67-a32d-26ac82edfb1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (463697182.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install openalexapi\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install openalexapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fff2aeb-883f-4f88-a239-b90e1082e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting purl\n",
      "  Downloading purl-1.6-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from purl) (1.16.0)\n",
      "Downloading purl-1.6-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: purl\n",
      "Successfully installed purl-1.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install purl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7ad6e76-4901-4d7e-8cec-8353ded85c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "A non-annotated attribute was detected: `base_url = 'https://api.openalex.org/'`. All model fields require a type annotation; if `base_url` is not meant to be a field, you may be able to resolve this error by annotating it as a `ClassVar` or updating `model_config['ignored_types']`.\n\nFor further information visit https://errors.pydantic.dev/2.8/u/model-field-missing-annotation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenalexapi\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openalexapi/__init__.py:9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenalexapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Work\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOpenAlex\u001b[39;00m(BaseModel):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This models the OpenAlex HTTP API\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    OpenAlex has 2 pools for clients.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Supplying your email will get you into the polite pool.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    :parameter=email\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     email: Optional[\u001b[38;5;28mstr\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:96\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[0;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m config_wrapper \u001b[38;5;241m=\u001b[39m ConfigWrapper\u001b[38;5;241m.\u001b[39mfor_model(bases, namespace, kwargs)\n\u001b[1;32m     95\u001b[0m namespace[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m config_wrapper\u001b[38;5;241m.\u001b[39mconfig_dict\n\u001b[0;32m---> 96\u001b[0m private_attributes \u001b[38;5;241m=\u001b[39m inspect_namespace(\n\u001b[1;32m     97\u001b[0m     namespace, config_wrapper\u001b[38;5;241m.\u001b[39mignored_types, class_vars, base_field_names\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m private_attributes \u001b[38;5;129;01mor\u001b[39;00m base_private_attributes:\n\u001b[1;32m    100\u001b[0m     original_model_post_init \u001b[38;5;241m=\u001b[39m get_model_post_init(namespace, bases)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_model_construction.py:401\u001b[0m, in \u001b[0;36minspect_namespace\u001b[0;34m(namespace, ignored_types, base_class_vars, base_class_fields)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[1;32m    398\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m requires a type annotation\u001b[39m\u001b[38;5;124m'\u001b[39m, code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-field-missing-annotation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[1;32m    402\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA non-annotated attribute was detected: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m`. All model fields require a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    403\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype annotation; if `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is not meant to be a field, you may be able to resolve this \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    404\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror by annotating it as a `ClassVar` or updating `model_config[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignored_types\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    405\u001b[0m                 code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-field-missing-annotation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    406\u001b[0m             )\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ann_name, ann_type \u001b[38;5;129;01min\u001b[39;00m raw_annotations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    410\u001b[0m         is_valid_privateattr_name(ann_name)\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m ann_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m private_attributes\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ann_type, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__module__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunctools\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    416\u001b[0m     ):\n",
      "\u001b[0;31mPydanticUserError\u001b[0m: A non-annotated attribute was detected: `base_url = 'https://api.openalex.org/'`. All model fields require a type annotation; if `base_url` is not meant to be a field, you may be able to resolve this error by annotating it as a `ClassVar` or updating `model_config['ignored_types']`.\n\nFor further information visit https://errors.pydantic.dev/2.8/u/model-field-missing-annotation"
     ]
    }
   ],
   "source": [
    "import openalexapi\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "import heapq\n",
    "import csv\n",
    "import os\n",
    "\n",
    "name_search = [\"david nathan\"]\n",
    "\n",
    "\n",
    "#Getting all author ids through search of first and last name:\n",
    "base_url = 'https://api.openalex.org/'\n",
    "def get_authorIDs(name):\n",
    "    listofIDs = []\n",
    "    page = 1\n",
    "    full_query= f'https://api.openalex.org/authors?search={name}&page={page}'\n",
    "    response = requests.get(full_query)\n",
    "    visualize_data = response.json()\n",
    "    num_pages = math.ceil(visualize_data['meta']['count']/25)\n",
    "    \n",
    "    while page <= num_pages:\n",
    "        full_query= f'https://api.openalex.org/authors?search={name}&page={page}'\n",
    "        response = requests.get(full_query)\n",
    "        visualize_data = response.json()\n",
    "        for result in visualize_data['results']:\n",
    "            openalex_id = result['id'].replace(\"https://openalex.org/\", \"\")\n",
    "            listofIDs.append(openalex_id)\n",
    "            \n",
    "            #for concepts in result['x_concepts']:\n",
    "                #if concepts['display_name'] == 'Medicine':\n",
    "        page += 1 \n",
    "\n",
    "    print(f'There are {len(listofIDs)} author ids for {name}')\n",
    "    return listofIDs\n",
    "\n",
    "#get_authorIDs(\"William pao\")\n",
    "\n",
    "\n",
    "#Finds all work_ids with given authorId\n",
    "def work_id(givenAuthorID):\n",
    "        page = 'page={}'\n",
    "        filtered_works_url = f'https://api.openalex.org/works?filter=author.id:{givenAuthorID}&{page}'\n",
    "        page = 1\n",
    "        has_more_pages = True\n",
    "        fewer_than_10000_results = True\n",
    "        all_worksID = []\n",
    "\n",
    "        # loop through pages\n",
    "        while has_more_pages and fewer_than_10000_results:\n",
    "\n",
    "            # set page value and request page from OpenAlex\n",
    "            url = filtered_works_url.format(page)\n",
    "            page_with_results = requests.get(url).json()\n",
    "\n",
    "            # loop through partial list of results\n",
    "            results = page_with_results['results']\n",
    "            for i,work in enumerate(results):\n",
    "                openalex_id = work['id'].replace(\"https://openalex.org/\", \"\")\n",
    "                all_worksID.append(openalex_id)\n",
    "            # next page\n",
    "            page += 1\n",
    "\n",
    "            # end loop when either there are no more results on the requested page \n",
    "            # or the next request would exceed 15 results\n",
    "            per_page = page_with_results['meta']['per_page']\n",
    "            has_more_pages = len(results) == per_page\n",
    "            fewer_than_10000_results = per_page * page <= 10000\n",
    "        print(f'There are {len(all_worksID)} works for {givenAuthorID}')\n",
    "        return (all_worksID)\n",
    "#work_id('A2250212419')\n",
    "\n",
    "#Tests if finding asci names and concepts works under a small scale\n",
    "#----------------------TESTER----------------- FOR THE findAAConcepts FUNCTION AFTER\n",
    "def findIndvConcepts(names):\n",
    "    authorsConcepts = {}\n",
    "    dir = os.path.dirname(os.path.realpath(\"Open_AlexMerging.ipynb\")).replace(\"open_alex_data\", \"asci_aap_data\")\n",
    "    os.chdir(dir)\n",
    "    with open(r\"asci_aap_dataJSONUpdated.json\") as fileJson:        \n",
    "        data = json.load(fileJson)\n",
    "        allData = data[\"people\"]\n",
    "\n",
    "    for name in names:\n",
    "        for indv in allData:\n",
    "            first = indv[\"first_name\"].lower()\n",
    "            last = indv[\"last_name\"].lower()\n",
    "            if (first+\" \"+last)== name.lower():                                               \n",
    "                authorsConcepts[name] = (ast.literal_eval(indv[\"original specialization\"]))\n",
    "            \n",
    "        if (name in authorsConcepts):\n",
    "            print(f'{name} successfully found')\n",
    "        else:\n",
    "            authorsConcepts[name] = []\n",
    "            print(f'{name} not found') \n",
    "\n",
    "    return authorsConcepts\n",
    "#findIndvConcepts([\"William Pao\",\n",
    "                  #\"Ashley You\",\n",
    "                  #\"Kjersti Aagaard\"])\n",
    "                  #\"E. Abel\",\n",
    "                  #\"Janis Abkowitz\"])\n",
    "\n",
    "\n",
    "#Goes through asci/aap data and gets name and concepts\n",
    "def findAAConcepts():\n",
    "    authorsConcepts = {}\n",
    "    dir = os.path.dirname(os.path.realpath(\"Open_AlexMerging.ipynb\")).replace(\"open_alex_data\", \"asci_aap_data\")\n",
    "    os.chdir(dir)\n",
    "    with open(r\"asci_aap_dataJSONUpdated.json\") as fileJson:        \n",
    "        data = json.load(fileJson)\n",
    "        allData = data[\"people\"]\n",
    "        print(f'There are {len(allData)} amount of people in ASCI/AAP json file')\n",
    "\n",
    "    for indv in allData:\n",
    "        first = indv[\"first_name\"].lower()\n",
    "        last = indv[\"last_name\"].lower()\n",
    "        name = first+\" \"+last\n",
    "        if len(indv[\"original specialization\"])!= 2:\n",
    "            authorsConcepts[name] = (ast.literal_eval(indv[\"original specialization\"]))\n",
    "    #new_dict = {key: value for key, value in authorsConcepts.items() if value}\n",
    "    print(f'There are {len(authorsConcepts)} amount of people with specialites listed in ASCI/AAP json file')\n",
    "    return authorsConcepts  \n",
    "#findAAConcepts()   \n",
    "\n",
    "def findAANames():\n",
    "    authors = []\n",
    "    dir = os.path.dirname(os.path.realpath(\"Open_AlexMerging.ipynb\")).replace(\"open_alex_data\", \"asci_aap_data\")\n",
    "    os.chdir(dir)\n",
    "    with open(r\"asci_aap_dataJSONUpdated.json\") as fileJson:        \n",
    "        data = json.load(fileJson)\n",
    "        allData = data[\"people\"]\n",
    "        print(f'There are {len(allData)} amount of people in ASCI/AAP json file')\n",
    "\n",
    "    for indv in allData:\n",
    "        first = indv[\"first_name\"].lower()\n",
    "        last = indv[\"last_name\"].lower()\n",
    "        name = first+\" \"+last\n",
    "        authors.append(name)\n",
    "    return authors  \n",
    "#findAANames()\n",
    "\n",
    "#finished\n",
    "#finds author concepts given list of names\n",
    "#filter through medicine \n",
    "def authorConcepts(people):\n",
    "    authors = {}\n",
    "    for name in people:\n",
    "        totalConcepts = []\n",
    "        authorIds = get_authorIDs(name)\n",
    "        for id in authorIds:\n",
    "            authorTopics= {}\n",
    "            tempConcepts = []\n",
    "            full_query= f'https://api.openalex.org/authors/{id}'\n",
    "            response = requests.get(full_query)\n",
    "            visualize_data = response.json()\n",
    "            for concepts in visualize_data[\"x_concepts\"]:\n",
    "                if (float(concepts['score']) >= 90.0 and float(concepts['level']) >= 1) or concepts['display_name']== \"Medicine\":\n",
    "                    tempConcepts.append(concepts['display_name'])\n",
    "            authorTopics[id]= tempConcepts\n",
    "            totalConcepts.append(authorTopics)\n",
    "        authors[name]= totalConcepts\n",
    "    return authors \n",
    "#authorConcepts(['Kjersti Aagaard'])\n",
    "\n",
    "\n",
    "#finds all work details given work id\n",
    "def findWork(workId):\n",
    "    fullquery = base_url+'works/'+workId\n",
    "    response = requests.get(fullquery)\n",
    "    visualize_data = response.json()\n",
    "    visualize_data.pop(\"abstract_inverted_index\")\n",
    "    visualize_data.pop(\"related_works\")\n",
    "    visualize_data.pop(\"ngrams_url\")\n",
    "    #clean the unicode\n",
    "    #visualize_data[\"\"]\n",
    "    return visualize_data\n",
    "#findWork('W2139236349')\n",
    "\n",
    "\n",
    "#finds work concepts given work link\n",
    "def workConcepts(workId):\n",
    "    totalDict = {}\n",
    "    totalWorkConcepts = []\n",
    "    allinfo = findWork(workId)\n",
    "    for concept in allinfo['concepts']:\n",
    "        if float(concept['score']) >= 0.3 and float(concept['level']) >= 2 or concept['display_name']== \"Medicine\" :\n",
    "            totalWorkConcepts.append(concept['display_name'])\n",
    "    totalDict[workId] = totalWorkConcepts\n",
    "\n",
    "    return totalDict\n",
    "#workConcepts(\"W2005052157\")\n",
    "\n",
    "\n",
    "#checks which concepts occur the most often in a work\n",
    "def checkConcepts(conceptlist):\n",
    "    count_dict = {}\n",
    "    for element in conceptlist:\n",
    "        if element!='Medicine':\n",
    "            if element in count_dict:\n",
    "                count_dict[element] += 1\n",
    "            else:\n",
    "                count_dict[element] = 1\n",
    "\n",
    "    # Find the three largest values\n",
    "    largest_values = heapq.nlargest(3, count_dict.values())\n",
    "\n",
    "    # Find the keys corresponding to the largest values, stores first 3\n",
    "    final_dict = {}\n",
    "    n = 0\n",
    "    for key, value in count_dict.items():\n",
    "        if n < 3:\n",
    "            if value in largest_values:\n",
    "                final_dict[key] = value\n",
    "                n += 1\n",
    "        else: \n",
    "             break\n",
    "    return final_dict\n",
    "\n",
    "testList= ['Medicine',\n",
    "  'Medicine', \n",
    "  'Medicine',\n",
    "  'Eosinophilic esophagitis',\n",
    "  'Budesonide',\n",
    "  'Internal medicine',\n",
    "  'Heartburn',\n",
    "  'Eosinophilia',\n",
    "  'Gastroenterology',\n",
    "  'Nausea',\n",
    "  'Vomiting',\n",
    "  'Corticosteroid',\n",
    "  'Adverse effect',\n",
    "  'Esophagitis',\n",
    "  'Eosinophilic esophagitis',\n",
    "  'Internal Medicine',\n",
    "  'Budesonide']\n",
    "#checkConcepts(testList)\n",
    "\n",
    "def findWorkConcepts(names): #keys(1. name, 2. authorId 3. workId)\n",
    "    #searches to get author ids\n",
    "    finalDict = {}\n",
    "    count = 0\n",
    "    for name in names:\n",
    "        authorIDs = get_authorIDs(name)\n",
    "        listofAuthors = []\n",
    "        for id in authorIDs:\n",
    "            tempDict = {}\n",
    "            tempWorkList = []\n",
    "            workIds = work_id(id)\n",
    "            for wID in workIds:\n",
    "               if 'Medicine' in workConcepts(wID)[wID]: #preliminary filter\n",
    "                tempWorkList.append(workConcepts(wID))\n",
    "               else: \n",
    "                   count +=1\n",
    "            tempDict[id] = tempWorkList\n",
    "            listofAuthors.append(tempDict)\n",
    "        finalDict[name] = listofAuthors\n",
    "    print(f'{count} amount of workIds did not have Medicine in their concepts')\n",
    "    return finalDict\n",
    "                \n",
    "    #searches to get work ids\n",
    "    #access work ids\n",
    "    #access concepts in work id\n",
    "    #loops through concepts in work id and saves it \n",
    "#findWorkConcepts([\"Seema Aceves\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa1bde-e1cf-40a8-9f7a-f562be236fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5467b22-066a-407b-8864-775e1a408371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
